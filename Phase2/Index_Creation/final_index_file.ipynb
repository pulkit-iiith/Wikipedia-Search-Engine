{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.sax\n",
    "import spacy\n",
    "from nltk.stem import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import sys\n",
    "from helper import *\n",
    "import math\n",
    "import copy\n",
    "import Stemmer\n",
    "import timeit\n",
    "import os \n",
    "import heapq\n",
    "import copy\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "stemming = Stemmer.Stemmer('english')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "r1 = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',re.DOTALL)\n",
    "r2 = re.compile(r'{\\|(.*?)\\|}',re.DOTALL)\n",
    "r3 = re.compile(r'{{v?cite(.*?)}}',re.DOTALL)\n",
    "r4 = re.compile(r'[-.,:;_?()\"/\\']',re.DOTALL)\n",
    "r5 = re.compile(r'\\[\\[file:(.*?)\\]\\]',re.DOTALL)\n",
    "catRegExp = r'\\[\\[category:(.*?)\\]\\]'\n",
    "r6 = re.compile(r'[\\'~` \\n\\\"_!=@#$%\\-^*+{\\[}\\]\\|\\\\<>/?]',re.DOTALL)\n",
    "r7 = re.compile(r'{{infobox(.*?)}}',re.DOTALL)\n",
    "r9 = re.compile(r'{{(.*?)}}',re.DOTALL)\n",
    "r10 = re.compile(r'<(.*?)>',re.DOTALL)\n",
    "r11=re.compile(r'\\[\\[(.*?)\\]\\]')\n",
    "r12=re.compile(catRegExp,re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.sax\n",
    "import subprocess\n",
    "import mwparserfromhell\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "inverted_index = {}\n",
    "no_of_words=0\n",
    "file_no=0\n",
    "word_count_in_page_no={}\n",
    "total_docs=30000\n",
    "total_titles=30000\n",
    "total_words=40000\n",
    "page_count=0\n",
    "\n",
    "_page_id=0\n",
    "title_file_no=0\n",
    "list_for_title=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiXmlHandler(xml.sax.handler.ContentHandler):\n",
    "    def __init__(self):\n",
    "        xml.sax.handler.ContentHandler.__init__(self)\n",
    "        self._buffer = None\n",
    "        self._values = {}\n",
    "        self._current_tag = None\n",
    "        self._pages = []\n",
    "#         self._page_id=0\n",
    "\n",
    "    def characters(self, content):\n",
    "        if self._current_tag:\n",
    "            self._buffer.append(content)\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name in ('title', 'text'):\n",
    "            self._current_tag = name\n",
    "            self._buffer = []\n",
    "\n",
    "    def endElement(self, name):\n",
    "        if name == self._current_tag:\n",
    "            self._values[name] = ' '.join(self._buffer)\n",
    "            \n",
    "        if name == 'title':\n",
    "\n",
    "            create_title(' '.join(self._buffer))\n",
    "\n",
    "        if name == 'page':\n",
    "            \n",
    "            self._pages.append((self._values['title'], self._values['text']))\n",
    "            create(self._pages[0])\n",
    "            self._pages=[]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_idf_for_word(doc_list):\n",
    "    total_doc=8796395\n",
    "    t_ct=1\n",
    "    c_ct=1\n",
    "    i_ct=1\n",
    "    r_ct=1\n",
    "    e_ct=1\n",
    "    b_ct=1\n",
    "    for doc in doc_list:\n",
    "        posting_t=re.findall(r't[0-9]*',doc,re.DOTALL)\n",
    "        posting_c=re.findall(r'c[0-9]*',doc,re.DOTALL)\n",
    "        posting_i=re.findall(r'i[0-9]+',doc,re.DOTALL)   #otherwise it might match with id123\n",
    "        posting_r=re.findall(r'r[0-9]*',doc,re.DOTALL)\n",
    "        posting_e=re.findall(r'e[0-9]*',doc,re.DOTALL)\n",
    "        posting_b=re.findall(r'b[0-9]*',doc,re.DOTALL)\n",
    "        \n",
    "        if(len(posting_t)):\n",
    "            t_ct+=1\n",
    "        if(len(posting_c)):\n",
    "            c_ct+=1\n",
    "        if(len(posting_i)):\n",
    "            i_ct+=1\n",
    "        if(len(posting_r)):\n",
    "            r_ct+=1\n",
    "        if(len(posting_e)):\n",
    "            e_ct+=1\n",
    "        if(len(posting_b)):\n",
    "            b_ct+=1\n",
    "    \n",
    "    idf_t=total_doc/t_ct\n",
    "    idf_t=round(math.log(1+idf_t,10),3)\n",
    "    \n",
    "    idf_c=total_doc/c_ct\n",
    "    idf_c=round(math.log(1+idf_c,10),3)\n",
    "    \n",
    "    idf_i=total_doc/i_ct\n",
    "    idf_i=round(math.log(1+idf_i,10),3)\n",
    "    \n",
    "    idf_r=total_doc/r_ct\n",
    "    idf_r=round(math.log(1+idf_r,10),3)\n",
    "    \n",
    "    idf_e=total_doc/e_ct\n",
    "    idf_e=round(math.log(1+idf_e,10),3)\n",
    "    \n",
    "    idf_b=total_doc/b_ct\n",
    "    idf_b=round(math.log(1+idf_b,10),3)\n",
    "    \n",
    "    idf_res=[idf_t,idf_c,idf_i,idf_r,idf_e,idf_b]\n",
    "    \n",
    "    return idf_res\n",
    "\n",
    "\n",
    "def tfidf_posting(tf_posting,field_idf_list):\n",
    "    tfidf_pos=\"\"\n",
    "#     print(tf_posting)\n",
    "#     print(field_idf_list)\n",
    "    \n",
    "    \n",
    "    docid=re.findall(r'D[0-9]*',tf_posting,re.DOTALL)\n",
    "#     docid=int(re.findall(r'[0-9]+',docid[0],re.DOTALL)[0])\n",
    "    tfidf_pos+=docid[0]       # doc id added\n",
    "    \n",
    "    t_pos=re.findall(r't[0-9]*',tf_posting,re.DOTALL)\n",
    "    if(len(t_pos)):\n",
    "        t_tf=int(re.findall(r'[0-9]+',t_pos[0],re.DOTALL)[0])\n",
    "        tfidf=int(math.floor(t_tf*field_idf_list[0]))\n",
    "        tfidf_pos+=\"t\"+str(tfidf)\n",
    "        \n",
    "    c_pos=re.findall(r'c[0-9]*',tf_posting,re.DOTALL)\n",
    "    if(len(c_pos)):\n",
    "        c_tf=int(re.findall(r'[0-9]+',c_pos[0],re.DOTALL)[0])\n",
    "        tfidf=int(math.floor(c_tf*field_idf_list[1]))\n",
    "        tfidf_pos+=\"c\"+str(tfidf)\n",
    "        \n",
    "    i_pos=re.findall(r'i[0-9]*',tf_posting,re.DOTALL)\n",
    "    if(len(i_pos)):\n",
    "        i_tf=int(re.findall(r'[0-9]+',i_pos[0],re.DOTALL)[0])\n",
    "        tfidf=int(math.floor(i_tf*field_idf_list[2]))\n",
    "        tfidf_pos+=\"i\"+str(tfidf)\n",
    "        \n",
    "    r_pos=re.findall(r'r[0-9]*',tf_posting,re.DOTALL)\n",
    "    if(len(r_pos)):\n",
    "        r_tf=int(re.findall(r'[0-9]+',r_pos[0],re.DOTALL)[0])\n",
    "        tfidf=int(math.floor(r_tf*field_idf_list[3]))\n",
    "        tfidf_pos+=\"r\"+str(tfidf)\n",
    "    \n",
    "    e_pos=re.findall(r'e[0-9]*',tf_posting,re.DOTALL)\n",
    "    if(len(e_pos)):\n",
    "        e_tf=int(re.findall(r'[0-9]+',e_pos[0],re.DOTALL)[0])\n",
    "        tfidf=int(math.floor(e_tf*field_idf_list[4]))\n",
    "        tfidf_pos+=\"e\"+str(tfidf)\n",
    "    \n",
    "    b_pos=re.findall(r'b[0-9]*',tf_posting,re.DOTALL)\n",
    "    if(len(b_pos)):\n",
    "        b_tf=int(re.findall(r'[0-9]+',b_pos[0],re.DOTALL)[0])\n",
    "        tfidf=int(math.floor(b_tf*field_idf_list[5]))\n",
    "        tfidf_pos+=\"b\"+str(tfidf)\n",
    "        \n",
    "        \n",
    "    return tfidf_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_title():\n",
    "    global title_file_no\n",
    "    global list_for_title\n",
    "    print(\"...................title......................\")\n",
    "    title_pointer=open(\"dumped_titles\"+\"/\"+str(title_file_no)+\".txt\",'w')\n",
    "    title_file_no+=1\n",
    "    for each in list_for_title:\n",
    "        title_pointer.write(each)\n",
    "    list_for_title=[]\n",
    "def create_title(title_content):\n",
    "#     print(title_content)\n",
    "    global title_file_no\n",
    "    global list_for_title\n",
    "    global total_titles\n",
    "    title_content+=\"\\n\"\n",
    "    list_for_title.append(title_content)\n",
    "#     print(list_for_title)\n",
    "    if(len(list_for_title)>=total_titles):\n",
    "        dump_title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_idf(last_record):\n",
    "#     total_pages_allowed=8796395\n",
    "#     doc_count = last_record[1].split(\"#\")\n",
    "#     idf = total_pages_allowed/len(doc_count)\n",
    "#     idf = math.log(1 + idf, 10)\n",
    "#     idf=round(idf,3)\n",
    "#     print(idf)\n",
    "#     print(doc_count)\n",
    "#     return idf,doc_count\n",
    "\n",
    "def merge_function(path_to_doc):\n",
    "#     print(\"maaddhhaaann\")\n",
    "    global total_words\n",
    "    count_of_files=0\n",
    "    count_of_words=0\n",
    "    \n",
    "    all_files=os.listdir(path_to_doc)\n",
    "    sz=len(all_files)\n",
    "    print(sz)\n",
    "    \n",
    "    material=os.listdir()\n",
    "    if(\"destination\" not in material):\n",
    "        os.mkdir(\"destination\")\n",
    "    \n",
    "    primary_index=open(\".\"+\"/\"+\"destination\"+\"/\"+str(count_of_files)+\".txt\",\"w\")\n",
    "    seconday_index=open(\"secondary.txt\",\"w\")\n",
    "    \n",
    "    list_of_file_ptrs=[]\n",
    "    for loc in range(sz):\n",
    "        pointers=open(\".\"+\"/\"+\"dumped_files\"+\"/\"+\"doc\"+str(loc)+\".txt\",\"r\")\n",
    "        list_of_file_ptrs.append(pointers)    \n",
    "    #remmember these are from 1 and files are created with name 0 \n",
    "    list_for_heap=[]\n",
    "    for loc in range(sz):\n",
    "        read=list_of_file_ptrs[loc].readline()\n",
    "#         print(read)\n",
    "#         print(\".........................................................\")\n",
    "        find_partition=read.index(\"#\")\n",
    "#         print(find_partition)\n",
    "        vocab=read[:find_partition]\n",
    "        posting=read[find_partition+1:]\n",
    "        posting=posting[:len(posting)-1]\n",
    "        fin_lis=[]\n",
    "        fin_lis.append(vocab)\n",
    "        fin_lis.append(posting)\n",
    "        fin_lis.append(loc)\n",
    "        list_for_heap.append(fin_lis)\n",
    "    heapq.heapify(list_for_heap)\n",
    "    \n",
    "    final_record=heapq.heappop(list_for_heap)     # first minimum popped out\n",
    "    last_record=copy.deepcopy(final_record)\n",
    "    \n",
    "\n",
    "    while(len(list_for_heap)>0):\n",
    "#         print(size_of_heap)\n",
    "        rd=list_of_file_ptrs[last_record[2]].readline()\n",
    "        if(rd !=\"\"):\n",
    "#             print(rd)\n",
    "            find_part=rd.index(\"#\")\n",
    "            voc=rd[:find_part]\n",
    "            post=rd[find_part+1:]\n",
    "            post=post[:len(post)-1]\n",
    "            nw_lis=[]\n",
    "            nw_lis.append(voc)\n",
    "            nw_lis.append(post)\n",
    "            nw_lis.append(last_record[2])\n",
    "            heapq.heappush(list_for_heap,nw_lis)\n",
    "        buffer_record=heapq.heappop(list_for_heap)           # deleting another node to check weather this belong to same\n",
    "                                                             # word in different document or not \n",
    "        \n",
    "        if(buffer_record[0]!=last_record[0]):\n",
    "            \n",
    "            docs=last_record[1].split(\"#\")\n",
    "            \n",
    "\n",
    "#             idf = total_docs/len(docs)              #overall idf         not needed\n",
    "#             idf = round(math.log(1 + idf, 10), 3)\n",
    "            \n",
    "            line_to_write=last_record[0]                   #word to be written \n",
    "            \n",
    "            field_idf_list=field_idf_for_word(docs)   # get field tfidf list here index 0=t,1=c,2=i,3=r,4=e,5=b\n",
    "            \n",
    "\n",
    "    \n",
    "            \n",
    "            for doc in docs:                        #modifying each doc's field tf to tfidf and writing to merged file\n",
    "                tf_posting_section=doc\n",
    "                if(len(tf_posting_section)>0):\n",
    "                    id_=re.findall('D',tf_posting_section,re.DOTALL)\n",
    "                    if(len(id_)):\n",
    "                        tfidf_posting_section= tfidf_posting(tf_posting_section,field_idf_list) #convert tf posting  part to tfidf posting part\n",
    "    \n",
    "                        line_to_write+=\"#\"+tfidf_posting_section #v.1\n",
    "                  \n",
    "            if(line_to_write!=last_record[0]):\n",
    "                primary_index.write(line_to_write+'\\n')\n",
    "                \n",
    "            if count_of_words==0:   #first time entry after write happpen so write the first word into secondary index\n",
    "                print(\"sec\")\n",
    "                seconday_index.write(last_record[0] + \"\\n\")  \n",
    "            count_of_words+=1    \n",
    "            if count_of_words==total_words:\n",
    "\n",
    "                count_of_words=0\n",
    "                count_of_files+=1\n",
    "                primary_index=open(\".\"+\"/\"+\"destination\"+\"/\"+str(count_of_files)+\".txt\",\"w\")\n",
    "                \n",
    "            last_record=buffer_record \n",
    "        else:\n",
    "            last_record[2]=buffer_record[2]\n",
    "            last_record[1]=last_record[1]+\"#\"+buffer_record[1]\n",
    "    print(\"merge complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enwiki-20200801-pages-articles-multistream23.xml-p29823661p30503450.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 211825\n",
      "enwiki-20200801-pages-articles-multistream6.xml-p565314p892912.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 402383\n",
      "enwiki-20200801-pages-articles-multistream23.xml-p28323661p29823660.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 880750\n",
      "enwiki-20200801-pages-articles-multistream10.xml-p2336423p3046512.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 1189197\n",
      "enwiki-20200801-pages-articles-multistream3.xml-p88445p200509.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 1271487\n",
      "enwiki-20200801-pages-articles-multistream22.xml-p23927984p25427983.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 1719297\n",
      "enwiki-20200801-pages-articles-multistream22.xml-p25427984p26823660.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 2113177\n",
      "enwiki-20200801-pages-articles-multistream15.xml-p9244801p9518048.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 2183742\n",
      "enwiki-20200801-pages-articles-multistream16.xml-p9518049p11018048.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................title......................\n",
      "....................................\n",
      "documents processed 2531634\n",
      "enwiki-20200801-pages-articles-multistream23.xml-p26823661p28323660.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 3010196\n",
      "enwiki-20200801-pages-articles-multistream19.xml-p16120543p17620542.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 3482986\n",
      "enwiki-20200801-pages-articles-multistream15.xml-p7744801p9244800.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 3903016\n",
      "enwiki-20200801-pages-articles-multistream17.xml-p11539267p13039266.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 4375761\n",
      "enwiki-20200801-pages-articles-multistream14.xml-p6197595p7697594.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 4802393\n",
      "enwiki-20200801-pages-articles-multistream19.xml-p17620543p18754735.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 5119990\n",
      "enwiki-20200801-pages-articles-multistream14.xml-p7697595p7744800.bz2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................title......................\n",
      "....................................\n",
      "documents processed 5132380\n",
      "enwiki-20200801-pages-articles-multistream5.xml-p352690p565313.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 5253246\n",
      "enwiki-20200801-pages-articles-multistream1.xml-p1p30303.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 5273043\n",
      "enwiki-20200801-pages-articles-multistream17.xml-p13039267p13693073.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 5464651\n",
      "enwiki-20200801-pages-articles-multistream18.xml-p13693074p15193073.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 5923147\n",
      "enwiki-20200801-pages-articles-multistream20.xml-p20254736p21222156.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 6179396\n",
      "enwiki-20200801-pages-articles-multistream7.xml-p892913p1268691.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 6374878\n",
      "enwiki-20200801-pages-articles-multistream13.xml-p5040437p6197594.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 6773187\n",
      "enwiki-20200801-pages-articles-multistream21.xml-p21222157p22722156.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 7226358\n",
      "enwiki-20200801-pages-articles-multistream9.xml-p1791080p2336422.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 7483094\n",
      "enwiki-20200801-pages-articles-multistream16.xml-p11018049p11539266.bz2\n",
      "...................title......................\n",
      "....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 7617885\n",
      "enwiki-20200801-pages-articles-multistream21.xml-p22722157p23927983.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 8025214\n",
      "enwiki-20200801-pages-articles-multistream18.xml-p15193074p16120542.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 8294862\n",
      "enwiki-20200801-pages-articles-multistream2.xml-p30304p88444.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 8333641\n",
      "enwiki-20200801-pages-articles-multistream8.xml-p1268692p1791079.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 8582177\n",
      "enwiki-20200801-pages-articles-multistream4.xml-p200510p352689.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 8666131\n",
      "enwiki-20200801-pages-articles-multistream11.xml-p3046513p3926861.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 9002538\n",
      "enwiki-20200801-pages-articles-multistream12.xml-p3926862p5040436.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 9378360\n",
      "enwiki-20200801-pages-articles-multistream20.xml-p18754736p20254735.bz2\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "...................title......................\n",
      "....................................\n",
      "documents processed 9829059\n",
      "enter merge\n",
      "346\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f09c2cd85e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"documents processed\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_page_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"enter merge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmerge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"dumped_files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-38527b712fa7>\u001b[0m in \u001b[0;36mmerge_function\u001b[0;34m(path_to_doc)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtf_posting_section\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mtfidf_posting_section\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtfidf_posting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_posting_section\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfield_idf_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#convert tf posting  part to tfidf posting part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-af95755fbb82>\u001b[0m in \u001b[0;36mtfidf_posting\u001b[0;34m(tf_posting, field_idf_list)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mdocid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'D[0-9]*'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf_posting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m#     docid=int(re.findall(r'[0-9]+',docid[0],re.DOTALL)[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mtfidf_pos\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m       \u001b[0;31m# doc id added\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mt_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr't[0-9]*'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf_posting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "i=0;\n",
    "temp=os.listdir()\n",
    "if \"dumped_files\" not in temp:\n",
    "    os.mkdir(\"dumped_files\")\n",
    "if \"dumped_titles\" not in temp:\n",
    "    os.mkdir(\"dumped_titles\")\n",
    "data_path=\"data/\"\n",
    "TOTAL_DATA=os.listdir(data_path)\n",
    "\n",
    "for data in TOTAL_DATA:\n",
    "#     if(i>=1):\n",
    "#         break\n",
    "    handler = WikiXmlHandler()\n",
    "    parser = xml.sax.make_parser()\n",
    "    parser.setContentHandler(handler)\n",
    "    print(data)\n",
    "#     i+=1\n",
    "#     if data == \"enwiki-20200801-pages-articles-multistream23.xml-p29823661p30503450.bz2\":\n",
    "#         continue\n",
    "    for line in subprocess.Popen(['bzcat'], \n",
    "                              stdin = open(data_path+data), \n",
    "                              stdout = subprocess.PIPE).stdout:\n",
    "        parser.feed(line)\n",
    "    \n",
    "#     dump_title()\n",
    "\n",
    "    if(len(inverted_index)>0):\n",
    "        dump_title()\n",
    "        start_dump()\n",
    "    print(\"documents processed\",_page_id)\n",
    "print(\"enter merge\")\n",
    "merge_function(\".\"+\"/\"+\"dumped_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "sec\n",
      "merge complete\n"
     ]
    }
   ],
   "source": [
    "merge_function(\".\"+\"/\"+\"dumped_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(word):\n",
    "    try:\n",
    "        word.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def clean(tokenList):\n",
    "    tokenList = ' '.join(tokenList)\n",
    "    tokenList = r4.sub(' ',tokenList)\n",
    "    tokenList = r5.sub(' ',tokenList)\n",
    "    tokenList = r6.sub(' ',tokenList)\n",
    "    tokenList = tokenList.split()\n",
    "    return tokenList\n",
    "\n",
    "def isValid(word):\n",
    "    if word == \"\" or word in stop_words or len(word) < 3:\n",
    "            return False\n",
    "    return validate(word)\n",
    "\n",
    "\n",
    "def process_digit(w):\n",
    "    if w.isnumeric():\n",
    "        w=w.lstrip('0')\n",
    "    return w  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_tf_for_field(TF,fraction):\n",
    "    TF=int((fraction+TF)*10000)\n",
    "    return TF\n",
    "\n",
    "\n",
    "\n",
    "def add_in_inverted_index(dict_,tag,page_id):\n",
    "    word_ctr_in_dict=0\n",
    "    for i in dict_:\n",
    "        word_ctr_in_dict+=dict_[i]\n",
    "    for i in dict_:\n",
    "        if i not in inverted_index:\n",
    "            inverted_index[i] = {}\n",
    "        if page_id not in inverted_index[i]:\n",
    "            inverted_index[i][page_id] = {}\n",
    "#         inverted_index[i][page_id][tag] = dict_[i]\n",
    "            \n",
    "        TF=dict_[i]/word_ctr_in_dict          #find tf corresponding to every tag/field\n",
    "        TF=round(math.log(1+TF,10),4)\n",
    "        \n",
    "        if tag==\"title\":\n",
    "            TF=find_tf_for_field(TF,.0100)       #priorities are assigned accordingly\n",
    "        elif tag==\"category\":\n",
    "            TF=find_tf_for_field(TF,.0050)\n",
    "        elif tag==\"infobox\":\n",
    "            TF=find_tf_for_field(TF,.0050)\n",
    "        elif tag==\"external_links\":\n",
    "            TF=find_tf_for_field(TF,.0010)\n",
    "        elif tag==\"references\":\n",
    "#             print(TF,\"r\")\n",
    "            TF=find_tf_for_field(TF,.0010)\n",
    "        elif tag==\"body\":\n",
    "            TF=find_tf_for_field(TF,.0001)\n",
    "        inverted_index[i][page_id][tag]=[dict_[i],TF]\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_tf(sentence,wrd_ctr,word_count_in_page_no,each_id):\n",
    "#     term_factor = wrd_ctr/word_count_in_page_no[each_id]\n",
    "#     term_factor = math.log(1 + term_factor, 10)\n",
    "# #     print(term_factor)\n",
    "#     term_factor = round(term_factor, 4)\n",
    "# #     print(term_factor)\n",
    "#     term_factor = int(((0.0001)+term_factor)*10000)\n",
    "# #     print(term_factor)\n",
    "#     sentence += \"*\" + str(term_factor)\n",
    "#     return sentence\n",
    "\n",
    "\n",
    "def start_dump():\n",
    "    print(\"....................................\")\n",
    "    global inverted_index\n",
    "    global no_of_words\n",
    "    global file_no\n",
    "    global page_count\n",
    "    dump_inverted_index()\n",
    "    inverted_index = {}\n",
    "    page_count=0\n",
    "    file_no+=1\n",
    "    word_count_in_page_no={}\n",
    "def dump_inverted_index(): \n",
    "    global file_no\n",
    "    global word_count_in_page_no\n",
    "    indices=inverted_index.keys()\n",
    "    indices=sorted(indices)\n",
    "    f= open(\".\"+\"/\"+\"dumped_files\"+\"/\"+\"doc\"+str(file_no)+\".txt\",\"w\")\n",
    "    for val in indices:\n",
    "#         wrd_ctr=0\n",
    "        sentence=\"\"\n",
    "        sentence+=str(val)\n",
    "        further_info=inverted_index[val]\n",
    "        document_ids=further_info.keys()\n",
    "        document_ids=sorted(document_ids)\n",
    "        for each_id in document_ids:\n",
    "            \n",
    "            sentence+=\"#\"+\"D\"+ str(each_id)\n",
    "            inverted_index[val][each_id].keys()\n",
    "#             print(inverted_index[val][each_id])\n",
    "#             print(list(inverted_index[val][each_id].keys())[0])\n",
    "#             print(list(inverted_index[val][each_id].keys()))\n",
    "            if(\"title\" in list(inverted_index[val][each_id].keys())):\n",
    "                sentence+=\"t\"+str(inverted_index[val][each_id][\"title\"][1])\n",
    "#                 print(\"t\")\n",
    "#                 wrd_ctr+=inverted_index[val][each_id][\"title\"][0]\n",
    "            if(\"body\" in list(inverted_index[val][each_id].keys())):\n",
    "                sentence+=\"b\"+str(inverted_index[val][each_id][\"body\"][1])\n",
    "#                 wrd_ctr+=inverted_index[val][each_id][\"body\"][0]\n",
    "#                 print(\"b\")\n",
    "            if(\"infobox\" in list(inverted_index[val][each_id].keys())):\n",
    "                sentence+=\"i\"+str(inverted_index[val][each_id][\"infobox\"][1])\n",
    "#                 wrd_ctr+=inverted_index[val][each_id][\"infobox\"][0]\n",
    "#                 print(\"i\")\n",
    "            if(\"category\" in list(inverted_index[val][each_id].keys())):\n",
    "                sentence+=\"c\"+str(inverted_index[val][each_id][\"category\"][1])\n",
    "#                 wrd_ctr+=inverted_index[val][each_id][\"category\"][0]\n",
    "#                 print(\"c\")\n",
    "            if(\"external_links\" in list(inverted_index[val][each_id].keys())):\n",
    "                sentence+=\"e\"+str(inverted_index[val][each_id][\"external_links\"][1])\n",
    "#                 wrd_ctr+=inverted_index[val][each_id][\"external_links\"][0]\n",
    "#                 print(\"e\")\n",
    "            if(\"references\" in list(inverted_index[val][each_id].keys())):\n",
    "                sentence+=\"r\"+str(inverted_index[val][each_id][\"references\"][1])\n",
    "#                 wrd_ctr+=inverted_index[val][each_id][\"references\"][0]\n",
    "#                 print(\"r\")\n",
    "#             print(each_id)\n",
    "#             sentence=find_tf(sentence,wrd_ctr,word_count_in_page_no,each_id)\n",
    "            \n",
    "            \n",
    "        f.write(sentence + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_preprocess(tex):\n",
    "    tex = tex.lower()\n",
    "    tex = r1.sub(' ', tex)\n",
    "    tex = r2.sub(' ', tex)\n",
    "    tex = r10.sub(' ', tex)\n",
    "    tex.replace('\\n', ' ')\n",
    "    tex= tex.strip()\n",
    "    return tex\n",
    "\n",
    "def intermediate_preprocess(tex):\n",
    "    tex = r3.sub(' ', tex)\n",
    "    return tex\n",
    "\n",
    "\n",
    "def fin_preprocess(tex):\n",
    "    tex = r4.sub(' ', tex)\n",
    "    tex = r5.sub(' ', tex)\n",
    "    tex = r6.sub(' ', tex)\n",
    "    tex = r7.sub(' ', tex)\n",
    "    tex = r9.sub(' ', tex)\n",
    "    tex = r11.sub(' ', tex)\n",
    "    tex = re.compile(r'\\[\\[category:(.*?)\\]\\]',re.DOTALL).sub(' ', tex)\n",
    "    tex = tex.split()\n",
    "    return tex\n",
    "\n",
    "def create(pge):\n",
    "    global page_count\n",
    "    global _page_id\n",
    "    page_count+=1\n",
    "#     print(page_count)\n",
    "    global word_count_in_page_no\n",
    "    word_count_for_page=0\n",
    "    Title_dict={}\n",
    "    Body_Text_dict={}\n",
    "    Infobox_dict={}\n",
    "    Categories_dict={}\n",
    "    External_Links_dict={}\n",
    "    References_dict={}\n",
    "    \n",
    "    page_id=_page_id\n",
    "    title=pge[0]\n",
    "    body=pge[1]\n",
    "    title=title.lower()\n",
    "    \n",
    "    body=initial_preprocess(body)\n",
    "    \n",
    "    \n",
    "    references=re.findall(r'{{v?cite(.*?)}}',body,re.DOTALL)\n",
    "\n",
    "\n",
    "    for i in references:\n",
    "        refer=re.findall(r'\\| ?title ?=(.*?)\\|',i,re.DOTALL) \n",
    "        str_refer=\"\"\n",
    "        str_refer=str_refer.join(refer)\n",
    "        ref_tok=str_refer.split()\n",
    "        token_list=clean(ref_tok)\n",
    "        token_list=stemming.stemWords(token_list)\n",
    "        for token in token_list:\n",
    "            word=token\n",
    "            if isValid(word):\n",
    "                word_count_for_page+=1\n",
    "                if word not in References_dict:\n",
    "                    References_dict[word]=1\n",
    "                else:\n",
    "                    References_dict[word]+=1\n",
    "\n",
    "        \n",
    "    body=intermediate_preprocess(body)\n",
    "    \n",
    "    \n",
    "    \n",
    "    linkcontent=re.findall(r'== ?external links ?==.*',body,re.DOTALL) \n",
    "\n",
    "    if len(linkcontent)!=0:\n",
    "        linkcontent=r11.sub(' ',linkcontent[0])\n",
    "        ll=re.findall(r'\\[(.*?)\\]', linkcontent, flags=re.MULTILINE)\n",
    "        link=clean(ll)\n",
    "        link=stemming.stemWords(link)\n",
    "        for l in link:\n",
    "            word=l\n",
    "            if isValid(word):\n",
    "                word_count_for_page+=1\n",
    "                if l not in External_Links_dict:\n",
    "                    External_Links_dict[l]=1\n",
    "                else:\n",
    "                    External_Links_dict[l]+=1\n",
    "    \n",
    "    \n",
    "    categories = re.findall(r'\\[\\[category:(.*?)\\]\\]', body, flags=re.MULTILINE)\n",
    "    \n",
    "    for category in categories:\n",
    "        tt = category.split()\n",
    "        token_list = clean(tt)\n",
    "        token_list=stemming.stemWords(token_list)\n",
    "        for token in token_list:\n",
    "            word=token\n",
    "#             word = stemmer.stem(token)\n",
    "            word.replace('\\n', ' ')\n",
    "            word= word.strip()\n",
    "#             word = remove_new_line(word)\n",
    "            if isValid(word):\n",
    "                word_count_for_page+=1\n",
    "                if word not in Categories_dict:\n",
    "                    Categories_dict[word] = 1\n",
    "                else:\n",
    "                    Categories_dict[word] += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    title = title.split()\n",
    "    title=clean(title)\n",
    "    title=stemming.stemWords(title)\n",
    "    for i in title:  \n",
    "#         word = stemmer.stem(i)  \n",
    "        word=i\n",
    "        if isValid(word):\n",
    "            word_count_for_page+=1\n",
    "            if word not in Title_dict:\n",
    "                Title_dict[word] = 1\n",
    "            else:\n",
    "                Title_dict[word] += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    infobox = re.findall(r'{{infobox(.*?)}}', body, re.DOTALL)\n",
    "    str_info=\"\"\n",
    "    str_info=str_info.join(infobox)\n",
    "    \n",
    "    pp=re.findall('^(.*?)\\|',str_info)\n",
    "    if(len(pp)>0):\n",
    "        Infobox_dict[pp[0].strip()] = 1\n",
    "    for infoList in infobox:\n",
    "        tt = re.findall(r'=(.*?)\\|',infoList,re.DOTALL)\n",
    "        token_list = clean(tt)\n",
    "        token_list=stemming.stemWords(token_list)\n",
    "        for token in token_list:\n",
    "#                 word = stemmer.stem(token)\n",
    "                word=token\n",
    "                word.replace('\\n', ' ')\n",
    "                word= word.strip()\n",
    "#                 word = remove_new_line(word)\n",
    "                \n",
    "                if isValid(word):\n",
    "                        word_count_for_page+=1\n",
    "                        if word not in Infobox_dict:\n",
    "                            Infobox_dict[word] = 1\n",
    "                        else:\n",
    "                            Infobox_dict[word] += 1\n",
    "        \n",
    "    \n",
    "    body=fin_preprocess(body)\n",
    "    fin_body=clean(body)\n",
    "\n",
    "    fin_body=stemming.stemWords(fin_body)\n",
    "    for token in fin_body:\n",
    "        word=token\n",
    "#         word = stemmer.stem(token)\n",
    "        word.replace('\\n', ' ')\n",
    "        word= word.strip()\n",
    "        if isValid(word):\n",
    "            word_count_for_page+=1\n",
    "            if word not in Body_Text_dict:\n",
    "                Body_Text_dict[word] = 1\n",
    "            else:\n",
    "                Body_Text_dict[word] += 1\n",
    "    \n",
    "    word_count_in_page_no[page_id]=word_count_for_page\n",
    "#     print(word_count_in_page_no)\n",
    "    \n",
    "    add_in_inverted_index(Title_dict, \"title\", page_id)\n",
    "    add_in_inverted_index(Body_Text_dict, \"body\", page_id)\n",
    "    add_in_inverted_index(Infobox_dict, \"infobox\", page_id)\n",
    "    add_in_inverted_index(Categories_dict, \"category\", page_id)\n",
    "    add_in_inverted_index(External_Links_dict, \"external_links\", page_id)\n",
    "    add_in_inverted_index(References_dict, \"references\", page_id)\n",
    "    \n",
    "\n",
    "    if(page_count == total_docs):\n",
    "#         print(\"happy\")\n",
    "        start_dump()\n",
    "    _page_id+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n",
      "j\n"
     ]
    }
   ],
   "source": [
    "l={1:\"e\",2:\"j\"}\n",
    "for i in l:\n",
    "    print(l[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=os.listdir(\"dumped_files\")\n",
    "l=sorted(l)\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
